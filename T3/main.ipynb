{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", 2000) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.\\\n",
    "    format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .load(\"./debate-tweets-001.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  (\"id\"\n",
    "            ,\"content\"\n",
    "            ,\"coordinate_0\"\n",
    "            ,\"coordiante_1\"\n",
    "            ,\"retweeted\"\n",
    "            ,\"tweet_id\"\n",
    "            ,\"tweet_id_str\"\n",
    "            ,\"created_at\"\n",
    "            ,\"created_at_str\"\n",
    "            ,\"in_reply_to_user_id\"\n",
    "            ,\"lang\"\n",
    "            ,\"place_name\"\n",
    "            ,\"place_id\"\n",
    "            ,\"place_bb_00\"\n",
    "            ,\"place_bb_01\"\n",
    "            ,\"place_bb_10\"\n",
    "            ,\"place_bb_11\"\n",
    "            ,\"place_bb_20\"\n",
    "            ,\"place_bb_21\"\n",
    "            ,\"place_bb_30\"\n",
    "            ,\"place_bb_31\"\n",
    "            ,\"place_type\"\n",
    "            ,\"place_country_code\"\n",
    "            ,\"place_country\"\n",
    "            ,\"place_full_name\"\n",
    "            ,\"user_name\"\n",
    "            ,\"user_id\"\n",
    "            ,\"user_id_str\"\n",
    "            ,\"user_location\"\n",
    "            ,\"user_friend_count\"\n",
    "            ,\"user_created_at\"\n",
    "            ,\"user_screen_name\")\n",
    "\n",
    "df = df.toDF(*columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Quais foram as hashtags mais usadas pela manhã, tarde e noite? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(s):\n",
    "    all_matches = re.findall(r'#\\w+', s)\n",
    "    return all_matches\n",
    "\n",
    "extract_hashtags = func.udf(extract, ArrayType(StringType()))\n",
    "\n",
    "df_hashtags = df \\\n",
    "    .filter(func.col('content').rlike('#\\w+')) \\\n",
    "    .withColumn('extracted', extract_hashtags('content')) \\\n",
    "    .select('created_at', func.explode_outer(func.col('extracted')) ) \\\n",
    "    .withColumnRenamed('col', 'hashtag')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, row_number, count, lit, desc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Período da Manhã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=====================================================>  (20 + 1) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             hashtag|count|\n",
      "+--------------------+-----+\n",
      "|   #EMABiggestFans1D|14818|\n",
      "|#EMABiggestFansJu...|14367|\n",
      "|             #trndnl|  604|\n",
      "|#VoteVampsTeenAwards|  365|\n",
      "|             #bomdia|  317|\n",
      "|         #QueroNoTVZ|  315|\n",
      "|             #BomDia|  306|\n",
      "|              #TwOff|  282|\n",
      "|#EMABiggestFansJu...|  231|\n",
      "|      #QuandoEuCasar|  146|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# filter: filtra linhas que contenham substring no campo 'created_at' com horarios entre 6 e 12 horas\n",
    "# groupby: agrupa hashatags repetidas\n",
    "# agg: função de agregação usada pra ordenar do maior numero de ocorrencias para o menor\n",
    "\n",
    "df_hashtags \\\n",
    "    .filter(func.col('created_at').substr(12,2).between(6,11)) \\\n",
    "    .groupBy('hashtag') \\\n",
    "    .agg(\n",
    "        func.count(func.lit(1)).alias('count')\n",
    "    ).orderBy(func.desc('count')) \\\n",
    "    .show(n=10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Período da Tarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:=====================================================>  (20 + 1) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             hashtag|count|\n",
      "+--------------------+-----+\n",
      "|   #EMABiggestFans1D|70859|\n",
      "|#EMABiggestFansJu...|60128|\n",
      "|        #StealMyGirl| 5704|\n",
      "|         #QueroNoTVZ| 5026|\n",
      "|   #bigpaynodanceoff| 1514|\n",
      "|  #AustinMahoneChile| 1230|\n",
      "|       #AustinMahone| 1111|\n",
      "|#demiyourstorydoe...| 1090|\n",
      "|             #trndnl| 1049|\n",
      "|    #HottieOfTheWeek|  925|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# filter: filtra linhas que contenham substring no campo 'created_at' com horarios entre 6 e 12 horas\n",
    "# groupby: agrupa hashatags repetidas\n",
    "# agg: função de agregação usada pra ordenar do maior numero de ocorrencias para o menor\n",
    "\n",
    "df_hashtags \\\n",
    "    .filter(func.col('created_at').substr(12,2).between(12,18)) \\\n",
    "    .groupBy('hashtag') \\\n",
    "    .agg(\n",
    "        func.count(func.lit(1)).alias('count')\n",
    "    ).orderBy(func.desc('count')) \\\n",
    "    .show(n=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Período da Noite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:=====================================================>  (20 + 1) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|             hashtag| count|\n",
      "+--------------------+------+\n",
      "|#EMABiggestFansJu...|133599|\n",
      "|   #EMABiggestFans1D|129768|\n",
      "|       #camilasayshi| 10507|\n",
      "|        #DebateNoSBT|  3416|\n",
      "|    #CartersNewVideo|  3207|\n",
      "|   #bigpaynodanceoff|  2878|\n",
      "|     #TheVoiceBrasil|  2819|\n",
      "|          #Vote5HEMA|  2666|\n",
      "|        #AssistamODR|  2545|\n",
      "|     #DebateNaRecord|  2494|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# filter: filtra linhas que contenham substring no campo 'created_at' com horarios entre 19 e 23 horas ou 0 e 5 horas\n",
    "# groupby: agrupa hashatags repetidas\n",
    "# agg: função de agregação usada pra ordenar do maior numero de ocorrencias para o menor\n",
    "\n",
    "df_hashtags \\\n",
    "    .filter(func.col('created_at').substr(12,2).between(19,23) | func.col('created_at').substr(12,2).between(0,5)) \\\n",
    "    .groupBy('hashtag') \\\n",
    "    .agg(\n",
    "        func.count(func.lit(1)).alias('count')\n",
    "    ).orderBy(func.desc('count')) \\\n",
    "    .dropna() \\\n",
    "    .show(n=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Quais as hashtags mais usadas em cada dia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------+-----+\n",
      "|timestamp |hashtag                    |count|\n",
      "+----------+---------------------------+-----+\n",
      "|null      |#EMABiggestFansJustinBieber|7    |\n",
      "|2014-10-15|#EMABiggestFans1D          |34547|\n",
      "|2014-10-16|#EMABiggestFans1D          |68633|\n",
      "|2014-10-17|#EMABiggestFansJustinBieber|49488|\n",
      "|2014-10-18|#EMABiggestFansJustinBieber|27454|\n",
      "|2014-10-19|#EMABiggestFansJustinBieber|33582|\n",
      "|2014-10-20|#EMABiggestFansJustinBieber|10452|\n",
      "+----------+---------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\") # Habilita formato de data com EEE\n",
    "w = Window.partitionBy('timestamp') # Window criada para usar filtro de maximo\n",
    "\n",
    "df_hashtags \\\n",
    "    .select('hashtag', func.to_timestamp(col('created_at'), 'EEE MMM dd HH:mm:ss ZZZZ yyyy').substr(0,10).alias('timestamp')) \\\n",
    "    .groupBy( 'timestamp','hashtag') \\\n",
    "    .agg(\n",
    "        func.count(func.lit(1)).alias('count'),\n",
    "    ).orderBy(func.desc('count')) \\\n",
    "    .withColumn('max', func.max('count').over(w)) \\\n",
    "    .where(func.col('count') == func.col('max')) \\\n",
    "    .drop('max') \\\n",
    "    .dropna() \\\n",
    "    .show(truncate=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Qual o número de tweets por hora a cada dia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:=====================================================>  (20 + 1) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|timestamp |number of tweets  |\n",
      "+----------+------------------+\n",
      "|2014-10-15|6041.916666666667 |\n",
      "|2014-10-16|12244.208333333334|\n",
      "|2014-10-17|10139.125         |\n",
      "|2014-10-18|7554.708333333333 |\n",
      "|2014-10-19|9477.791666666666 |\n",
      "|2014-10-20|3134.625          |\n",
      "+----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# contar quantidade de tweets por dia\n",
    "# agrupar por dia\n",
    "# dividir quantidade por 24\n",
    "\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\") # Habilita formato de data com EEE\n",
    "\n",
    "df_hashtags \\\n",
    "    .select(func.to_timestamp(col('created_at'), 'EEE MMM dd HH:mm:ss ZZZZ yyyy').substr(0,10).alias('timestamp')) \\\n",
    "    .groupBy( 'timestamp') \\\n",
    "    .agg(\n",
    "        func.count(func.lit(1)).alias('count'),\n",
    "    ) \\\n",
    "    .withColumn('number of tweets', func.col('count') / 24) \\\n",
    "    .drop('count') \\\n",
    "    .dropna() \\\n",
    "    .show(truncate=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb5ef3cb5c4fba3235c1cadbd587631132299defed20910895aebb886de3d707"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
