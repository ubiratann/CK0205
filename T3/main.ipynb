{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/11 17:44:05 WARN Utils: Your hostname, ip-172-31-77-113 resolves to a loopback address: 127.0.1.1; using 172.31.77.113 instead (on interface eth0)\n",
      "22/12/11 17:44:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/11 17:44:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Criando sessao no spark\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"Debate Tweets\") \\\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", 2000) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Carregando dataframe\n",
    "df = spark.read.\\\n",
    "    format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .load(\"./debate-tweets-001.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  (\"id\"\n",
    "            ,\"content\"\n",
    "            ,\"coordinate_0\"\n",
    "            ,\"coordiante_1\"\n",
    "            ,\"retweeted\"\n",
    "            ,\"tweet_id\"\n",
    "            ,\"tweet_id_str\"\n",
    "            ,\"created_at\"\n",
    "            ,\"created_at_str\"\n",
    "            ,\"in_reply_to_user_id\"\n",
    "            ,\"lang\"\n",
    "            ,\"place_name\"\n",
    "            ,\"place_id\"\n",
    "            ,\"place_bb_00\"\n",
    "            ,\"place_bb_01\"\n",
    "            ,\"place_bb_10\"\n",
    "            ,\"place_bb_11\"\n",
    "            ,\"place_bb_20\"\n",
    "            ,\"place_bb_21\"\n",
    "            ,\"place_bb_30\"\n",
    "            ,\"place_bb_31\"\n",
    "            ,\"place_type\"\n",
    "            ,\"place_country_code\"\n",
    "            ,\"place_country\"\n",
    "            ,\"place_full_name\"\n",
    "            ,\"user__screen_name\"\n",
    "            ,\"user_id\"\n",
    "            ,\"user_id_str\"\n",
    "            ,\"user_location\"\n",
    "            ,\"user_friend_count\"\n",
    "            ,\"user_created_at\"\n",
    "            ,\"user_name\")\n",
    "\n",
    "df = df.toDF(*columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Quais foram as hashtags mais usadas pela manhã, tarde e noite? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foi necesssária a criação de uma UDF function visto que um tweet pode conter mais de uma '#' e o método regex_extract seleciona apenas a PRIMEIRA ocorrência do regex.\n",
    "\n",
    "def extract(s):\n",
    "    all_matches = re.findall(r'#\\w+', s)\n",
    "    return all_matches\n",
    "\n",
    "extract_hashtags = func.udf(extract, ArrayType(StringType()))\n",
    "\n",
    "# .filter: fará com que apenas sentenças com # sejam selecionadas\n",
    "# .withcolumn: cria a coluna 'extracted', que é uma lista com as hashtags encontradas em cada tweet usando a funcao extract_hashtags\n",
    "# .select: seleciona\n",
    "#       1. data de criação\n",
    "#       2. .explode_outer: para transformar cada item da coluna 'extracted' em uma nova linha na coluna hashtag\n",
    "\n",
    "df_hashtags = df \\\n",
    "    .filter(func.col('content').rlike('#\\w+')) \\\n",
    "    .withColumn('extracted', extract_hashtags('content')) \\\n",
    "    .select('created_at', func.explode_outer(func.col('extracted')).alias('hashtag') )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Período da Manhã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:=====================================================>  (20 + 1) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             hashtag|count|\n",
      "+--------------------+-----+\n",
      "|   #EMABiggestFans1D|14818|\n",
      "|#EMABiggestFansJu...|14367|\n",
      "|             #trndnl|  604|\n",
      "|#VoteVampsTeenAwards|  365|\n",
      "|             #bomdia|  317|\n",
      "|         #QueroNoTVZ|  315|\n",
      "|             #BomDia|  306|\n",
      "|              #TwOff|  282|\n",
      "|#EMABiggestFansJu...|  231|\n",
      "|      #QuandoEuCasar|  146|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# .filter: filtra linhas que contenham substring no campo 'created_at' com horarios entre 6 e 12 horas\n",
    "# .groupBy: agrupa hashatags repetidas\n",
    "# .count: cria coluna 'count' com contador da agrupação\n",
    "# .sort: ordena dataframe usando a coluna count\n",
    "# .show: mostra o dataframe\n",
    "\n",
    "df_hashtags \\\n",
    "    .filter(func.col('created_at').substr(12,2).between(6,11)) \\\n",
    "    .groupBy('hashtag') \\\n",
    "    .count() \\\n",
    "    .sort('count', ascending=0) \\\n",
    "    .show(n=20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Período da Tarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:=====================================================>  (20 + 1) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             hashtag|count|\n",
      "+--------------------+-----+\n",
      "|   #EMABiggestFans1D|70859|\n",
      "|#EMABiggestFansJu...|60128|\n",
      "|        #StealMyGirl| 5704|\n",
      "|         #QueroNoTVZ| 5026|\n",
      "|   #bigpaynodanceoff| 1514|\n",
      "|  #AustinMahoneChile| 1230|\n",
      "|       #AustinMahone| 1111|\n",
      "|#demiyourstorydoe...| 1090|\n",
      "|             #trndnl| 1049|\n",
      "|    #HottieOfTheWeek|  925|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# .filter: filtra linhas que contenham substring no campo 'created_at' com horarios entre 6 e 12 horas\n",
    "# .groupby: agrupa hashatags repetidas\n",
    "# .count: cria coluna 'count' com contador da agrupação\n",
    "# .sort: ordena dataframe usando a coluna count\n",
    "# .show: mostra o dataframe\n",
    "\n",
    "df_hashtags \\\n",
    "    .filter(func.col('created_at').substr(12,2).between(12,18)) \\\n",
    "    .groupBy('hashtag') \\\n",
    "    .count() \\\n",
    "    .sort('count', ascending=0) \\\n",
    "    .show(n=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Período da Noite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:=====================================================>  (20 + 1) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|             hashtag| count|\n",
      "+--------------------+------+\n",
      "|#EMABiggestFansJu...|133599|\n",
      "|   #EMABiggestFans1D|129768|\n",
      "|       #camilasayshi| 10507|\n",
      "|        #DebateNoSBT|  3416|\n",
      "|    #CartersNewVideo|  3207|\n",
      "|   #bigpaynodanceoff|  2878|\n",
      "|     #TheVoiceBrasil|  2819|\n",
      "|          #Vote5HEMA|  2666|\n",
      "|        #AssistamODR|  2545|\n",
      "|     #DebateNaRecord|  2494|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# .filter: filtra linhas que contenham substring no campo 'created_at' com horarios entre 19 e 23 horas ou 0 e 5 horas\n",
    "# .groupby: agrupa hashatags repetidas\n",
    "# .count: cria coluna 'count' com contador da agrupação\n",
    "# .sort: ordena dataframe usando a coluna count\n",
    "# .show: mostra o dataframe\n",
    "\n",
    "df_hashtags \\\n",
    "    .filter(func.col('created_at').substr(12,2).between(19,23) | func.col('created_at').substr(12,2).between(0,5)) \\\n",
    "    .groupBy('hashtag') \\\n",
    "    .count() \\\n",
    "    .sort('count', ascending=0) \\\n",
    "    .dropna() \\\n",
    "    .show(n=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Quais as hashtags mais usadas em cada dia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------+-----+\n",
      "|timestamp |hashtag                    |count|\n",
      "+----------+---------------------------+-----+\n",
      "|null      |#EMABiggestFansJustinBieber|7    |\n",
      "|2014-10-15|#EMABiggestFans1D          |34547|\n",
      "|2014-10-16|#EMABiggestFans1D          |68633|\n",
      "|2014-10-17|#EMABiggestFansJustinBieber|49488|\n",
      "|2014-10-18|#EMABiggestFansJustinBieber|27454|\n",
      "|2014-10-19|#EMABiggestFansJustinBieber|33582|\n",
      "|2014-10-20|#EMABiggestFansJustinBieber|10452|\n",
      "+----------+---------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Habilita formato de data com EEE\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\") \n",
    "\n",
    "# Window criada para usar filtro de máximo entre os grupos\n",
    "w = Window.partitionBy('timestamp') \n",
    "\n",
    "\n",
    "# .dropna: exclui linhas com valores nulos\n",
    "# .select: seleciona as colunas:\n",
    "#    1. hashtag\n",
    "#    2. cria coluna timestampo com base na coluna created_at\n",
    "# .groupBy: agrupa por timestamp de criação e hashtag\n",
    "# .count: cria coluna 'count' com contador da agrupação\n",
    "# .sort: ordena dataframe usando a coluna count\n",
    "# .withColumn: cria coluna max, que terá a quantidade maxima de cada grupo\n",
    "# .where: filtra apenas os maximos\n",
    "# .drop: exclui coluna com os maximos\n",
    "# .show: mostra o datafram\n",
    "\n",
    "df_hashtags \\\n",
    "    .dropna() \\\n",
    "    .select('hashtag', func.to_timestamp(func.col('created_at'), 'EEE MMM dd HH:mm:ss ZZZZ yyyy').substr(0,10).alias('timestamp')) \\\n",
    "    .groupBy( 'timestamp','hashtag') \\\n",
    "    .count() \\\n",
    "    .sort('count', ascending=0) \\\n",
    "    .withColumn('max', func.max('count').over(w)) \\\n",
    "    .where(func.col('count') == func.col('max')) \\\n",
    "    .drop('max') \\\n",
    "    .show(truncate=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Qual o número de tweets por hora a cada dia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:=====================================================>  (20 + 1) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|timestamp |number of tweets  |\n",
      "+----------+------------------+\n",
      "|2014-10-15|6041.916666666667 |\n",
      "|2014-10-16|12244.208333333334|\n",
      "|2014-10-17|10139.125         |\n",
      "|2014-10-18|7554.708333333333 |\n",
      "|2014-10-19|9477.791666666666 |\n",
      "|2014-10-20|3134.625          |\n",
      "+----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# contar quantidade de tweets por dia\n",
    "# agrupar por dia\n",
    "# dividir quantidade por 24\n",
    "\n",
    "# Habilita formato de data com EEE\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\") \n",
    "\n",
    "# .select: seleciona coluna com timestamp criado a partir da coluna created_at\n",
    "# .groupBy: agrupa pela data\n",
    "# .agg: cria coluna 'count' que é um contador de tweets por dia\n",
    "# .withColumn: cria coluna 'number of tweets' com quantidade de tweets por hora a cada dia (count / 24)\n",
    "# .drop: exclui coluna de contador geral\n",
    "# .show: mostra o datafram\n",
    "\n",
    "df_hashtags \\\n",
    "    .dropna() \\\n",
    "    .select(func.to_timestamp(func.col('created_at'), 'EEE MMM dd HH:mm:ss ZZZZ yyyy').substr(0,10).alias('timestamp')) \\\n",
    "    .groupBy( 'timestamp') \\\n",
    "    .count() \\\n",
    "    .withColumn('number of tweets', func.col('count') / 24) \\\n",
    "    .drop('count') \\\n",
    "    .show(truncate=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Quais as principais sentenças relacionadas à palavra “Dilma”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .select: seleciona apenas a coluna content\n",
    "# .fiter: filtra a coluna content com expressões que deem match com a palabra Dilma\n",
    "# .groupBy: agrupa dados pela coluna content\n",
    "# .count: cria coluna 'count' com contage baseado no goupby\n",
    "# .sort: ordena de forma decrescente\n",
    "# .show: mostra o dataframe\n",
    "df \\\n",
    "    .select('content') \\\n",
    "    .filter(func.col('content').rlike('Dilma')) \\\n",
    "    .groupBy('content') \\\n",
    "    .count() \\\n",
    "    .sort('count', ascending=0) \\\n",
    "    .show(truncate=0, n = 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Quais as princiapais sentenças relacionadas à palavra \"Aécio\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .select: seleciona apenas a coluna content\n",
    "# .fiter: filtra a coluna content com expressões que deem match com a palabra Dilma\n",
    "# .groupBy: agrupa dados pela coluna content\n",
    "# .count: cria coluna 'count' com contage baseado no goupby\n",
    "# .sort: ordena de forma decrescente\n",
    "# .show: mostra o dataframe\n",
    "df \\\n",
    "    .select('content') \\\n",
    "    .filter(func.col('content').rlike('Aécio')) \\\n",
    "    .groupBy('content') \\\n",
    "    .count() \\\n",
    "    .sort('count', ascending=0) \\\n",
    "    .show(truncate=0, n = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb5ef3cb5c4fba3235c1cadbd587631132299defed20910895aebb886de3d707"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
